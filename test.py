import torch
import cv2
import numpy as np
from transformers import TimesformerForVideoClassification, AutoImageProcessor  # Import ƒë√∫ng

# T·∫£i m√¥ h√¨nh TimeSformer ƒë√£ hu·∫•n luy·ªán tr√™n Kinetics-400
model_name = "facebook/timesformer-base-finetuned-k400"
model = TimesformerForVideoClassification.from_pretrained(model_name)
processor = AutoImageProcessor.from_pretrained(model_name)  # D√πng AutoImageProcessor thay th·∫ø

model.eval()  # ƒê∆∞a m√¥ h√¨nh v·ªÅ ch·∫ø ƒë·ªô ƒë√°nh gi√°

# H√†m tr√≠ch xu·∫•t frames t·ª´ video
def extract_frames(video_path, num_frames=8):
    cap = cv2.VideoCapture(video_path)
    frames = []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    if total_frames == 0:
        print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc video ho·∫∑c video r·ªóng!")
        return None

    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)

    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Chuy·ªÉn v·ªÅ RGB
        frames.append(frame)

    cap.release()
    return frames if len(frames) == num_frames else None

# H√†m hi·ªÉn th·ªã video
def show_video(video_path):
    cap = cv2.VideoCapture(video_path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        cv2.imshow("Video", frame)
        if cv2.waitKey(25) & 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()

# H√†m d·ª± ƒëo√°n h√†nh ƒë·ªông
def predict_action(video_path):
    show_video(video_path)  # Hi·ªÉn th·ªã video tr∆∞·ªõc khi nh·∫≠n d·∫°ng
    frames = extract_frames(video_path, num_frames=8)
    if frames is None:
        print("‚ùå Video qu√° ng·∫Øn ho·∫∑c l·ªói khi tr√≠ch xu·∫•t frames.")
        return

    inputs = processor(images=frames, return_tensors="pt")  # Ti·ªÅn x·ª≠ l√Ω frames
    with torch.no_grad():
        outputs = model(**inputs)

    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=1).item()

    # Load nh√£n c·ªßa Kinetics-400
    with open("kinetics_400_labels.txt", "r") as f:
        labels = [line.strip() for line in f.readlines()]

    print("üìå D·ª± ƒëo√°n h√†nh ƒë·ªông:", labels[predicted_class])

# Ch·∫°y nh·∫≠n d·∫°ng v·ªõi video ƒë·∫ßu v√†o
if __name__ == "__main__":
    video_path = "V_997.mp4"  # ƒê·ªïi th√†nh ƒë∆∞·ªùng d·∫´n video c·ªßa b·∫°n
    predict_action(video_path)
